{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install and Import packages"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1e83f06c1de74b2"
      },
      "id": "1e83f06c1de74b2"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.45.0-py2.py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.45.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        }
      ],
      "source": [
        "\n",
        "! pip install wandb"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:01:26.059801Z",
          "start_time": "2024-04-12T03:01:24.846567Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be348e0bfb157c",
        "outputId": "188021ae-91bb-437f-ba69-80c04fe237ac"
      },
      "id": "be348e0bfb157c",
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "import random\n",
        "import collections\n",
        "from time import time\n",
        "import copy\n",
        "import math"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:09.156842Z",
          "start_time": "2024-04-12T03:02:09.154677Z"
        },
        "id": "afc815861d75e9ce"
      },
      "id": "afc815861d75e9ce",
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check environment"
      ],
      "metadata": {
        "collapsed": false,
        "id": "da4c44fb48d262e5"
      },
      "id": "da4c44fb48d262e5"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# check if the system is running on colab or macbook m1 pro\n",
        "import platform\n",
        "import os\n",
        "op_system = platform.system()\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:01:26.065771Z",
          "start_time": "2024-04-12T03:01:26.064198Z"
        },
        "id": "71684418f401d651"
      },
      "id": "71684418f401d651",
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6b368a97601cce09"
      },
      "id": "6b368a97601cce09"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if op_system == 'Darwin':\n",
        "    # Macbook\n",
        "    data_path = '../../data/translation/wmt14-en-de/'\n",
        "elif op_system == 'Linux':\n",
        "    # Colab\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    data_path = '/content/drive/MyDrive/colab_data/from_scratch/data/translation/wmt14-en-de/'"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:10.621760Z",
          "start_time": "2024-04-12T03:02:10.619671Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abee6ce01d812c0a",
        "outputId": "7738e1ab-cab7-4a2d-f561-0aa0882cdf2e"
      },
      "id": "abee6ce01d812c0a",
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "collapsed": false,
        "id": "f4963a316123c0d5"
      },
      "id": "f4963a316123c0d5"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b40b5a0ac49149f5bbc940cba6e2f108"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e349826e352d481e9d6c71868f51de60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b32de8bba8747299743eefef9395c14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd53f2f2981d425d9da130c3ba65ee38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6067593c9694fe9918dcc6b239546bd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "run_name = \"self_implemented_transformer_not_converging\"\n",
        "wandb_project_name = \"from_scratch_transformer_colab\"\n",
        "\n",
        "check_point_folder_path = data_path + \"/check_point\"\n",
        "\n",
        "device_type = \"cuda\"\n",
        "if not torch.cuda.is_available():\n",
        "  if op_system == 'Darwin':\n",
        "    device_type = \"mps\"\n",
        "  elif op_system == 'Linux':\n",
        "    device_type = \"cpu\"\n",
        "device = torch.device(device_type)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32 if device_type == \"mps\" else 12\n",
        "SEQ_LEN = 64 if device_type == \"mps\" else 512\n",
        "ENCODER_LAYER_NUM = 6\n",
        "DECODER_LAYER_NUM = 6\n",
        "D_MODEL = 256 if device_type == \"mps\" else 512\n",
        "HIDDEN_DIM = 512 if device_type == \"mps\" else 2048\n",
        "NUM_HEADS = 8\n",
        "DROPOUT = 0.1\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\",pad_token=\"<pad>\",bos_token=\"<sos>\",eos_token=\"<eos>\",\n",
        "                                                       add_bos_token=True, add_eos_token=True,max_length=SEQ_LEN, padding=\"max_length\")\n",
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EPOCHS = 50 if device_type == \"mps\" else 3\n",
        "STEPS = 1000000\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.98\n",
        "EPSILON = 1e-9\n",
        "LEARNING_RATE = 0.00001\n",
        "WARMUP_STEPS = 4000\n",
        "TRAIN_DATA_SIZE = 5000 if device_type == \"mps\" else \"all\"\n",
        "TEST_DATA_SIZE = 1000 if device_type == \"mps\" else \"all\"\n",
        "\n",
        "STEP_LOSS_REPORT = 100 if device_type == \"mps\" else 200\n",
        "TEST_BLEU_REPORT = 200 if device_type == \"mps\" else 2000\n",
        "REPORT_WANDB = False if device_type in [\"mps\", \"cpu\"] else True\n",
        "seed_value = 42\n",
        "torch.manual_seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:11.192241Z",
          "start_time": "2024-04-12T03:02:10.951403Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299,
          "referenced_widgets": [
            "b40b5a0ac49149f5bbc940cba6e2f108",
            "099911e68c6b4c5dbabc4db6b7fff959",
            "d214c16c699f4882a7751b779ab24308",
            "c5baa30234f643deb5fd5a7c9b2eb497",
            "55f521fa9c0745c4803142039e44fd88",
            "f1489b6fe08e46a28960e85c8d1f8343",
            "a220915e38d3426482e138718686136f",
            "b92791da28024a5393ebca22885f6ccc",
            "7f5269ef126c4071afb2cff676103852",
            "4f3e9764a0c04f90941e25877e0c7e33",
            "beab08e9aa984211938466c0efff8466",
            "e349826e352d481e9d6c71868f51de60",
            "ad251a3a3269474da70939d0bc80f5a7",
            "3205734c81554c0fa38386e24efbd33e",
            "f8bde81ee8bc4f38bbc7083ba1a7cf77",
            "b4bb5a1212b14da7a06a8bd93ceaefbb",
            "2b001b38b55447e68d785b37e8ddfdab",
            "ece66e52d1c74fd39b6545a4c134bb81",
            "b1480cbba1584e34801f1bb83c3af111",
            "70127ca7070842d1a76aae6001b8bb09",
            "6782b7bf62514d968967479ebee368f3",
            "6a52feaca2bc47c4b27a32768b85a7f2",
            "2b32de8bba8747299743eefef9395c14",
            "71beacc4109c431c8327cf2b7ca62101",
            "beedee31a2044be286a1421a98df7b2c",
            "fece2e8f323d4368a5f8e590942ac0c3",
            "048449adf5d7404ab23e16d8374967ba",
            "49bf62aed09541128e2e473c0e769276",
            "870203723c034efd9fe931aa7a5efe2e",
            "b4dbcfee8e7d4daaa717038de868dbd2",
            "597e276606e24ff9a6ebc6e605cf8626",
            "a2b0ea5a539e45daa98736a09b33c2fb",
            "efabc108040d4cd58514a31faabefa0c",
            "fd53f2f2981d425d9da130c3ba65ee38",
            "e054484115a94a79b0ae3cae1b7955e5",
            "f3c7ea0dd40742beafeea3411e3ae840",
            "1244c3ad28c74dceb827533a5b8f08c5",
            "048c9f0b8dc042fda9841b27c76b4fca",
            "34693d93ed3244ee9f522c2018b11bbc",
            "da9022b798b44275916b6b143cb9604b",
            "f2903b1052f840b7bb25e6b635fe59cc",
            "ef612a2381de42dcb4f56dbc3c84da3c",
            "0e2785c13fb146cfa5d2ed77fa778584",
            "083726e595424387ac44239933aab106",
            "e6067593c9694fe9918dcc6b239546bd",
            "b142be0d847a4e17b90c5897fc3a536e",
            "0678cbcdad69441584b7cbe46338192d",
            "094e33cbfde246378e3cfb90ea7a45f6",
            "bb1f1ff7b57042d6841e54818460d84f",
            "44d1d93cb6b84703b9b611fe0831e548",
            "25f68f9763414b09bb4165acc9e97a42",
            "0033e0512aef4e1a90323b4a6904d3e6",
            "860f2e878c584b4ca959dc204faf87cf",
            "1f3c4895c02944428a27db7fb68f6c0e",
            "08aadb7691424a409c849b52cd4422f4"
          ]
        },
        "id": "10292570894400b0",
        "outputId": "39b0efc9-66d5-4adc-ee2c-f7547778a862"
      },
      "id": "10292570894400b0",
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50260\n",
            "cuda\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(len(tokenizer.vocab))\n",
        "print(device_type)\n",
        "print(device)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:11.194892Z",
          "start_time": "2024-04-12T03:02:11.193098Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c7f94a7255ff990",
        "outputId": "fab1b84a-e265-4be5-ebc0-8a3c8c5b870c"
      },
      "id": "6c7f94a7255ff990",
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "collapsed": false,
        "id": "d7df1049127ff6ca"
      },
      "id": "d7df1049127ff6ca"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loader"
      ],
      "metadata": {
        "collapsed": false,
        "id": "cfd5e5347d48da09"
      },
      "id": "cfd5e5347d48da09"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class WMT14ENDEDatasetHuggingFace(data.Dataset):\n",
        "\n",
        "    def __init__(self, en_raw_file_path= \"\",de_raw_file_path=\"\",\n",
        "               max_len=512, device=\"cuda\",data_size:str=\"all\"):\n",
        "        self.device = device\n",
        "        if data_size == \"all\":\n",
        "            data_size = \"all\"\n",
        "        else:\n",
        "            data_size = int(data_size)\n",
        "        with open(en_raw_file_path, \"r\") as f:\n",
        "            if data_size != \"all\":\n",
        "                en_sentence = f.readlines()[:data_size]\n",
        "            else:\n",
        "                en_sentence = f.readlines()\n",
        "        with open(de_raw_file_path, \"r\") as f:\n",
        "            if data_size !=\"all\":\n",
        "                de_sentence = f.readlines()[:data_size]\n",
        "            else:\n",
        "                de_sentence = f.readlines()\n",
        "        assert len(en_sentence) == len(de_sentence), \"The number of english and german sentences should be the same\"\n",
        "        self.data = list(zip(en_sentence, de_sentence))\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"gpt2\",pad_token=\"<pad>\",bos_token=\"<sos>\",eos_token=\"<eos>\",\n",
        "                                                       add_bos_token=True, add_eos_token=True,max_length=max_len)\n",
        "        self.tokenizer.add_special_tokens({\"pad_token\": \"<pad>\", \"bos_token\": \"<sos>\", \"eos_token\": \"<eos>\"})\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        en_sentence_str,de_sentence_str = self.data[idx]\n",
        "        en_sentence_str = \"<sos> \" + en_sentence_str.strip() + \" <eos>\"\n",
        "        de_sentence_str = \"<sos> \" + de_sentence_str.strip() + \" <eos>\"\n",
        "\n",
        "        # run huggingface tokenizer\n",
        "        en_sentence = self.tokenizer(en_sentence_str, padding=\"max_length\", truncation=True,\n",
        "                                     max_length=self.max_len, return_tensors=\"pt\",add_special_tokens=True)\n",
        "        de_sentence = self.tokenizer(de_sentence_str, padding=\"max_length\", truncation=True,\n",
        "                                     max_length=self.max_len, return_tensors=\"pt\",add_special_tokens=True\n",
        "                                     )\n",
        "\n",
        "\n",
        "        en_sentence_id = en_sentence[\"input_ids\"].squeeze().to(self.device)\n",
        "        de_sentence_id = de_sentence[\"input_ids\"].squeeze().to(self.device)\n",
        "        en_padding_mask = en_sentence[\"attention_mask\"].squeeze().to(self.device)\n",
        "        de_padding_mask = de_sentence[\"attention_mask\"].squeeze().to(self.device)\n",
        "        return {\n",
        "            \"en_input_ids\": en_sentence_id,\n",
        "            \"de_input_ids\": de_sentence_id,\n",
        "            \"en_padding_mask\": en_padding_mask,\n",
        "            \"de_padding_mask\": de_padding_mask,\n",
        "            \"en_sentence_str\": en_sentence_str,\n",
        "            \"de_sentence_str\": de_sentence_str\n",
        "        }"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:11.595434Z",
          "start_time": "2024-04-12T03:02:11.590559Z"
        },
        "id": "61a7bea559c8ef2e"
      },
      "id": "61a7bea559c8ef2e",
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation BLEU Score\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "cecf33a22ba5f1dd"
      },
      "id": "cecf33a22ba5f1dd"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "\n",
        "def _get_ngrams(segment, max_order):\n",
        "    \"\"\"\n",
        "    Extracts all n-grams up to a given maximum order from an input segment.\n",
        "\n",
        "    :param segment:\n",
        "        text segment from which n-grams will be extracted\n",
        "        list of tokens\n",
        "        [\"token1\", \"token2\", \"token3\", \"token4\", \"token5\"]\n",
        "    :param max_order:\n",
        "        maximum length of n-grams\n",
        "    :return:\n",
        "        a Counter with n-gram counts\n",
        "    \"\"\"\n",
        "    # create a counter to store the n-gram counts\n",
        "    ngram_counts = collections.Counter()\n",
        "    # run through all the n-gram from 1 to max_order\n",
        "    for order in range(1, max_order + 1):\n",
        "        # run through all the n-gram in the segment\n",
        "        for i in range(len(segment) - order + 1):\n",
        "            # get the n-gram, need to convert the n-gram to tuple since list is not hashable\n",
        "            ngram = tuple(segment[i:i + order])\n",
        "            # increment the n-gram count\n",
        "            ngram_counts[ngram] += 1\n",
        "    # return the n-gram counts, in which the key is the form 1 to max_order n-gram, the value is the frequency of the\n",
        "    # n-gram\n",
        "    return ngram_counts\n",
        "\n",
        "def compute_bleu(reference_corpus, translation_corpus, max_order=4,\n",
        "                 smooth=False, smooth_value=0.0):\n",
        "    \"\"\"\n",
        "     Implementation of BLEU score.\n",
        "    :param reference_corpus:\n",
        "        list of list of reference sentences, each sentence is a list of tokens\n",
        "        1 st level: number of \"list of reference sentences\", len is the number of translations\n",
        "        [\n",
        "            [\n",
        "                [\"token1\", \"token2\", \"token3\", \"token4\", \"token5\"],\n",
        "                [\"token1\", \"token2\", \"token3\"]\n",
        "            ],\n",
        "            [\n",
        "                [\"token1\", \"token2 \", \"token3\", \"token4\", \"token5\"],\n",
        "                [\"token1\", \"token2\", \"token3\"]\n",
        "            ]\n",
        "        ]\n",
        "        2 nd level: number of \"reference sentences\" for a single translation, len is the number of references\n",
        "        [\n",
        "            [\"token1\", \"token2\", \"token3\", \"token4\", \"token5\"],\n",
        "            [\"token1\", \"token2\", \"token3\"]\n",
        "        ]\n",
        "        3 rd level: number of tokens in a single reference sentence, len is the number of tokens in a single sentence\n",
        "        [\"token1\", \"token2\", \"token3\", \"token4\", \"token5\"]\n",
        "    :param translation_corpus:\n",
        "        list of translated sentences, each sentence is a list of tokens, those sentences are the predicted sentences\n",
        "        that we want to evaluate\n",
        "        1 st level: number of \"list of translated sentences\", len is the number of translations\n",
        "        [\n",
        "            [\"token1\", \"token2\", \"token3\", \"token4\", \"token5\"],\n",
        "            [\"token1\", \"token2\", \"token3\"]\n",
        "        ]\n",
        "        2 nd level: number of tokens in a single translated sentence, len is the number of tokens in a single sentence\n",
        "        [\"token1\", \"token2\", \"token3\", \"token4\", \"token5\"]\n",
        "    :param max_order:\n",
        "        the maximum n-gram order to use when computing BLEU score, usually 4\n",
        "    :param smooth:\n",
        "        whether to apply smoothing, default is False, if do not apply smoothing, then the n-gram modified\n",
        "        precision will be 0 if there is no n-gram overlap, that will make the log of 0, which is undefineda\n",
        "    :param smooth_value:\n",
        "        the value to use when applying smoothing, default is 0.0\n",
        "    :return:\n",
        "        the BLEU score, the value is between 0 and 1, the higher, the better\n",
        "    \"\"\"\n",
        "\n",
        "    matches_by_order = [0] * max_order\n",
        "    possible_matches_by_order = [0] * max_order\n",
        "    reference_length = 0\n",
        "    translation_length = 0\n",
        "\n",
        "    for (references, translation) in zip(reference_corpus, translation_corpus):\n",
        "        # when compute the brevity penalty, we have to consider the shortest reference sentence\n",
        "        # for the translation sentences, we need to add them up\n",
        "        reference_length += min(len(r) for r in references)\n",
        "        translation_length += len(translation)\n",
        "\n",
        "        # create a counter to store the n-gram counts of the merged reference sentences\n",
        "        merged_ref_ngram_counts = collections.Counter()\n",
        "        for reference in references:\n",
        "            # compute the n-gram counts of every reference sentence, and merge them\n",
        "            # the merge is not accumulative, it is the keep the maximum count of the n-gram\n",
        "            # for counter, the + operator will sum the count of the same key, where the | operator will keep the maximum\n",
        "            merged_ref_ngram_counts |= _get_ngrams(reference, max_order)\n",
        "        # get the n-gram counts of the translation sentence\n",
        "        translation_ngram_counts = _get_ngrams(translation, max_order)\n",
        "        # get the n-gram overlap of the translation sentence and the merged reference sentences\n",
        "        # the & operator will return the minimum count of the n-gram, if the n-gram is not in the merged reference\n",
        "        # sentences, then the count will be 0\n",
        "        overlap = translation_ngram_counts & merged_ref_ngram_counts\n",
        "\n",
        "        for ngram in overlap:\n",
        "            # increment the n-gram overlap count\n",
        "            # len(ngram) is to calculate the order of the n-gram, since the n-gram is a tuple, the length of the tuple\n",
        "            # minus 1 will be the order of the n-gram\n",
        "            matches_by_order[len(ngram) - 1] += overlap[ngram]\n",
        "        for order in range(1, max_order + 1):\n",
        "            # when calculate precision of the n-gram, we have to consider the possible matches as the denominator\n",
        "            # if the sentence len is x, then the possible n-gram is x - order + 1\n",
        "            possible_matches = len(translation) - order + 1\n",
        "            # to avoid the division by 0, we have to check if the possible matches is greater than 0,\n",
        "            # that only happens when the order is greater than the length of the sentence\n",
        "            # for example, if the sentence is [\"the\", \"cat\"], the possible bigram is 1, the possible trigram is 0\n",
        "            if possible_matches > 0:\n",
        "                # increment the possible n-gram matches count\n",
        "                possible_matches_by_order[order - 1] += possible_matches\n",
        "        precision = [0] * max_order\n",
        "        for i in range(0,max_order):\n",
        "            if smooth:\n",
        "                # if one of the n-gram order has no possible matches, then the precision will be 0\n",
        "                # but we have to avoid the division by 0, so we have to add a smooth value\n",
        "                precision[i] = (matches_by_order[i] + smooth_value) / (possible_matches_by_order[i] + smooth_value)\n",
        "            else:\n",
        "                if possible_matches_by_order[i] > 0:\n",
        "                    precision[i] = matches_by_order[i] / possible_matches_by_order[i]\n",
        "                else:\n",
        "                    precision[i] = 0\n",
        "\n",
        "        if min(precision) > 0:\n",
        "            # the reason using geometric mean is that the n-gram precision is highly correlated\n",
        "            # if they are independent, then we could use the arithmetic mean, but if the triple-gram precision is high,\n",
        "            # then the bigram precision will be high, so we have to use the geometric mean\n",
        "\n",
        "            # but using geometric mean will make the result underflow, since the precision is between 0 and 1\n",
        "            # we will multiply a number between 0 and 1 multiple times, the result will be really small\n",
        "            # so we have to use the log to avoid the underflow\n",
        "            # and at the end, we have to use exp to get the final result back, since log then exp will cancel each other\n",
        "            p_log_sum = sum((1 / max_order) * math.log(p) for p in precision)\n",
        "            geo_mean = math.exp(p_log_sum)\n",
        "        else:\n",
        "            geo_mean = 0\n",
        "\n",
        "        # compute the brevity penalty\n",
        "        ratio =  float(translation_length) / reference_length\n",
        "        if ratio > 1.0:\n",
        "            bp = 1\n",
        "        else:\n",
        "            bp = math.exp(1 - 1.0 / ratio)\n",
        "        bleu = geo_mean * bp\n",
        "    return {\"bleu\": bleu, \"geo_mean\": geo_mean, \"bp\": bp,\"unigram\": precision[0], \"bigram\": precision[1],\n",
        "            \"trigram\": precision[2], \"fourgram\": precision[3]}"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:11.904458Z",
          "start_time": "2024-04-12T03:02:11.898662Z"
        },
        "id": "7760449b72ef49c1"
      },
      "id": "7760449b72ef49c1",
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "collapsed": false,
        "id": "53f9770c1d8e0971"
      },
      "id": "53f9770c1d8e0971"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "\n",
        "def clone(component: nn.Module, num_of_copy: int) -> nn.ModuleList:\n",
        "    \"\"\"\n",
        "    In the transformer structure, there will a lot of repeat component, for example, the identical layer of encoders and\n",
        "    decoders. In order to create those identical components, we will need this clone function to create a list ModuleList\n",
        "    :param component: the component will be copied\n",
        "    :param num_of_copy: the number of copies will be in the final module list\n",
        "    :return: a module list contain num_of_copy component\n",
        "    \"\"\"\n",
        "    return nn.ModuleList([copy.deepcopy(component) for _ in range(num_of_copy)])\n",
        "\n",
        "\n",
        "def _get_padding_mask(attention_mask: torch.Tensor, dtype: torch.dtype) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    The padding mask is used to prevent the model to look at the padding token\n",
        "    :param attention_mask:\n",
        "        the mask is generated by tokenizer, usually the dim is [batch_size * seq_len] contains of 1 and 0, where 1\n",
        "        represent the position of the corresponding sentence is a meaningful token, otherwise it is a padding.\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # create padding mask\n",
        "    # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "\n",
        "    attention_mask = attention_mask[:, None, None, :]\n",
        "    attention_mask = 1.0 - attention_mask\n",
        "    attention_mask = attention_mask.masked_fill(attention_mask.to(torch.bool), torch.finfo(dtype).min)\n",
        "    return attention_mask\n",
        "\n",
        "\n",
        "def _get_causal_mask(attention_mask: torch.Tensor, input_shape, dtype: torch.dtype,\n",
        "                     ) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    The causal mask is used in decoder, the mask is used to prevent the model to look ahead the future token\n",
        "    :param attention_mask:\n",
        "        the mask is generated by tokenizer, usually the dim is [batch_size * seq_len] contains of 1 and 0, where 1\n",
        "        represent the position of the corresponding sentence is a meaningful token, otherwise it is a padding.\n",
        "    :param input_shape:\n",
        "        the shape of the input tensor, tuple of batch_size and seq_len of decoder input\n",
        "    :param inputs_embeds:\n",
        "        the embedding of the input tensor, the dim of the input tensor is [batch_size * seq_len * d_model]\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # add the past_key_values_length to the seq_len of the input tensor\n",
        "    key_value_length = input_shape[-1]\n",
        "\n",
        "    # 4d mask is passed through the layers\n",
        "    # if the attention_mask is 2D,\n",
        "\n",
        "    input_shape = (attention_mask.shape[0], input_shape[-1])\n",
        "\n",
        "    # create causal mask\n",
        "    # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "    causal_4d_mask = None\n",
        "    if input_shape[-1] > 1:\n",
        "        if key_value_length is None:\n",
        "            raise ValueError(\n",
        "                \"This attention mask converter is causal. Make sure to pass `key_value_length` to correctly create a causal mask.\"\n",
        "            )\n",
        "\n",
        "        bsz, tgt_len = input_shape\n",
        "        # create a mat that have the same size as attention weight\n",
        "        mask = torch.full((tgt_len, tgt_len), torch.finfo(dtype).min, device=attention_mask.device)\n",
        "        # rang a one dim mat only on conditional\n",
        "        mask_cond = torch.arange(mask.size(-1), device=attention_mask.device)\n",
        "        mask.masked_fill_(mask_cond < (mask_cond + 1).view(mask.size(-1), 1), 0)\n",
        "\n",
        "        mask = mask.to(dtype)\n",
        "\n",
        "        causal_4d_mask = mask[None, None, :, :].expand(bsz, 1, tgt_len, tgt_len)\n",
        "\n",
        "        # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "\n",
        "        bsz, src_len = attention_mask.size()\n",
        "        tgt_len = tgt_len if tgt_len is not None else src_len\n",
        "\n",
        "        expanded_mask = attention_mask[:, None, None, :].expand(bsz, 1, tgt_len, src_len).to(dtype)\n",
        "\n",
        "        inverted_mask = 1.0 - expanded_mask\n",
        "\n",
        "        expanded_attn_mask = inverted_mask.masked_fill(inverted_mask.to(torch.bool), torch.finfo(dtype).min)\n",
        "\n",
        "        if causal_4d_mask is not None:\n",
        "            expanded_attn_mask = causal_4d_mask.masked_fill(expanded_attn_mask.bool(), torch.finfo(dtype).min)\n",
        "\n",
        "        # expanded_attn_mask + causal_4d_mask can cause some overflow\n",
        "        expanded_4d_mask = expanded_attn_mask\n",
        "\n",
        "    return expanded_4d_mask"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:12.262931Z",
          "start_time": "2024-04-12T03:02:12.258279Z"
        },
        "id": "3c16910aff5971fe"
      },
      "id": "3c16910aff5971fe",
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Config Class"
      ],
      "metadata": {
        "collapsed": false,
        "id": "75764cb9bd3486ed"
      },
      "id": "75764cb9bd3486ed"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class TransformerConfig:\n",
        "    \"\"\"\n",
        "    The config class is an easy way to parse those hyper params into model\n",
        "    Since nowadays model architecture could be really deep, packing all the hypers into one config obj and pass this obj\n",
        "    from one component to deeper component is more neat than every __init__ func have a bunch of param\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 d_model: int = 512,\n",
        "                 num_heads: int = 8,\n",
        "                 dropout: float = 0.1,\n",
        "                 batch_size: int = 16,\n",
        "                 seq_len: int = 256,\n",
        "                 d_ff: int = 2048,\n",
        "                 vocab_size: int = 37000,\n",
        "                 device: str = \"cuda\",\n",
        "                 encoder_layer_num: int = 6,\n",
        "                 decoder_layer_num: int = 6,\n",
        "                 eps: float = 1e-6\n",
        "                 ):\n",
        "        # the main model size of the transformer model, in the whole model,  we will use d_model number vector to\n",
        "        # represent meaning of the word (the location of this word in the word embedding space)\n",
        "        self.d_model = d_model\n",
        "        # number of the heads define when we do the attention operation, parallel, there will be [num_heads] heads using\n",
        "        # the same inputs but different learnable params to the same operation, the concat res will be the final res of\n",
        "        # attention operation\n",
        "        self.num_heads = num_heads\n",
        "        # the dropout layer is critical in deep learning model, dropout is fantastic technical that can proven the\n",
        "        # model overfit. what the dropout layer doing is it \"cover/cut\" random a percentage of input when it is\n",
        "        # running, so the model won't over-relay on a certain feature/path of the model. it will increase the\n",
        "        # robustness of the model\n",
        "        self.dropout = dropout\n",
        "        self.batch_size = batch_size\n",
        "        # seq_len is the max number of token the model could process in one operation, not like RNN the model process\n",
        "        # the input token by token, all the attention computation in transformer could be done at teh same time, we have\n",
        "        # to define the max number of token, so the model can create weight mat accordingly\n",
        "        self.seq_len = seq_len\n",
        "        # the inner layer dim of fully-connected feed-forward component\n",
        "        self.d_ff = d_ff\n",
        "        # the vocab size of the tokenized, will be used to generate embedding layer and final fully connected layer\n",
        "        self.vocab_size = vocab_size\n",
        "        # indicate where the whole model will be running, all the tensor involved in the computation need to be moved\n",
        "        # on the same device\n",
        "        self.device = device\n",
        "        self.encoder_layer_num = encoder_layer_num\n",
        "        self.decoder_layer_num = decoder_layer_num\n",
        "        self.eps = eps"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:12.660670Z",
          "start_time": "2024-04-12T03:02:12.657770Z"
        },
        "id": "b6ae951e8256481c"
      },
      "id": "b6ae951e8256481c",
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MultiHeadAttention"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9eceba978435e2d8"
      },
      "id": "9eceba978435e2d8"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi Head attention is a foundation component of transformer model,\n",
        "    What is does just repeat the scaled dot product attention operation several times parallel, each time we call it a\n",
        "    Head\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: TransformerConfig, is_cross: bool = False):\n",
        "\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        # since those head are doing the attention operation at the same time, we better put them in a same matrix\n",
        "        # to make it efficient. In that case, if we define single head dim as d_single_head\n",
        "        # d_model = num_heads * d_single_head. before we do the scaled dot-product we have to assert, otherwise we can't\n",
        "        # split the d_model evenly into heads\n",
        "        self.d_model = config.d_model\n",
        "        self.num_heads = config.num_heads\n",
        "        assert self.d_model % self.num_heads == 0, \"the number of head need to be divided by d_model\"\n",
        "        # this linear nn.ModuleList contains the W_q,W_k,W_v,W_o. All of them have the same size the purpose the W_q,\n",
        "        # W_k,W_v is for projection. to do the scale dot-production attention, we have to use query(q) * key(k) to\n",
        "        # get score between q and k then use the score as weight to retrieve info from the v, but there is an issue,\n",
        "        # the original input the attention is general. For example in self attention, the original input of attention\n",
        "        # is the same, 3 identical matrix represent a general meaning of the sentence. to get a better result. We\n",
        "        # want project the general meaning into a specific space (query space, key space and value space) and use\n",
        "        # those projected(professional) value to do the scale dot-product this W_o is used when we concat and\n",
        "        # aggregate each head's value into final attention res since those head might have the same result,\n",
        "        # some may focus on less important relation between q and k, we need a learnable params to assign weight to\n",
        "        # each head and their dim\n",
        "        self.linears = clone(nn.Linear(self.d_model, self.d_model), 4)\n",
        "        self.dropout = nn.Dropout(p=config.dropout)\n",
        "        self.seq_len = config.seq_len\n",
        "        self.d_k = self.d_model // self.num_heads\n",
        "        self.is_cross = is_cross\n",
        "\n",
        "    def _scaled_dot_product(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor,\n",
        "                            mask: torch.Tensor, dropout: nn.Dropout) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        this function will actually do the scaled dot product mentioned in equation (1)\n",
        "        for this function, all q k v need to be prepared, which it has already been split into head dim\n",
        "        for the mask, it also should adjust to proper dim for broadcasting operation\n",
        "        :param q: [batch_size * num_heads * seq_len * d_k]\n",
        "        :param k: [batch_size * num_heads * seq_len * d_k]\n",
        "        :param v: [batch_size * num_heads * seq_len * d_k]\n",
        "        :param mask: [ batch_size * 1 * seq_len * 1]\n",
        "        :param dropout: the dropout defined in the outer layer\n",
        "        :return: the scaled dot-product result [batch_size * num_heads * seq_len * d_k]\n",
        "        \"\"\"\n",
        "        d_k = q.size(-1)\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "        if mask is not None:\n",
        "            # TODO explain the mask fill and why there is a small value\n",
        "            scores = scores + mask\n",
        "        scores = F.softmax(scores, dim=-1)\n",
        "        # TODO explain why dropout before\n",
        "        return torch.matmul(scores, v)\n",
        "\n",
        "    def forward(self, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor,\n",
        "                mask: torch.Tensor = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        this function implement the function in section 3.2.2\n",
        "        :param q:[batch_size * seq_len * d_model]\n",
        "        :param k:[batch_size * seq_len * d_model]\n",
        "        :param v:[batch_size * seq_len * d_model]\n",
        "        :param mask:[batch_size * seq_len]\n",
        "        :param is_decoder: if the component is decoder, the mask should be different\n",
        "        :return: result of multi head attention [batch_size * seq_len * d_model]\n",
        "        \"\"\"\n",
        "        # get the batch since the q k v need to be reshaped latter. the number of sentence in the batch won't be all the\n",
        "        # time the same, for example, the last batch may not be full\n",
        "        batch_size = q.size(0)\n",
        "        # TODO explain why have mask here\n",
        "\n",
        "        # the mask is generated by tokenizer, usually the dim is [batch_size * seq_len] contains of 1 and 0\n",
        "        # where 1 represent the position of the corresponding sentence is a meaningful token, otherwise it is a\n",
        "        # padding. in order to use it, mask_fill the score, it has to meet the requirement of broadcasting with score\n",
        "        # since the dim of score is [batch_size * num_heads * seq_len * d_k], the mask has to un-squeeze at dim 1 and\n",
        "        # dim -1\n",
        "        if mask is not None:\n",
        "            if self.is_cross and self.training:\n",
        "                # get the causal mask, the mask is used to prevent the model to look ahead the future token\n",
        "                # the dim of the mask is already [ 1 * 1 * seq_len * seq_len]\n",
        "                # the shape of the mask is [batch_size * 1 * key_len * memory_len]\n",
        "\n",
        "                mask = _get_causal_mask(attention_mask=mask,\n",
        "                                        input_shape = mask.size(),\n",
        "                                        dtype=q.dtype)\n",
        "\n",
        "            else:\n",
        "                # the mask is used to prevent the model to look at the padding token\n",
        "                # the dim of the mask is already [batch_size * 1 * seq_len * 1]\n",
        "                if not self.training:\n",
        "                    mask = _get_padding_mask(attention_mask=mask, dtype=q.dtype)\n",
        "                else:\n",
        "                    mask = _get_padding_mask(attention_mask=mask, dtype=q.dtype)\n",
        "\n",
        "        query, key, value = [l(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2) for l, x in\n",
        "                             zip(self.linears, (q, k, v))]\n",
        "        x = self._scaled_dot_product(query, key, value, mask=mask, dropout=self.dropout)\n",
        "        # project the input q,k,v into according space to get actual query, key and value\n",
        "        # q, k, v = [w(mat) for mat, w in zip([q, k, v], self.linears)]\n",
        "        # reshape the q , k  and v to into heads, constitute the multi head\n",
        "        # q, k, v = [mat.view(batch_size, self.seq_len, self.num_heads, -1) for mat in [q, k, v]]\n",
        "        # transpose the number since the matmul only work on last two dim, to calculate the attention, we want to\n",
        "        # compute q [...... seq_len * d_q] * k [..... d_k, seq_len]\n",
        "        # after reshaping, the dim is [batch_size * seq_len, num_heads, d_k]\n",
        "        # so dim 1 and dim 2 need to transpose\n",
        "        # q, k, v = [torch.transpose(mat, 1, 2) for mat in [q, k, v]]\n",
        "        # after everything be prepared, the scaled dot-product will be conducted.\n",
        "        # the output of that func is split into head, we need transpose the dim back and reshape the same dim\n",
        "        # as the input, so in the transformer the following identical layer could keeping do the same attention\n",
        "        # operation again and again\n",
        "\n",
        "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
        "        # TODO why need contiguous()\n",
        "        # x = (self._scaled_dot_product(q=q, k=k, v=v, mask=mask, dropout=self.dropout)\n",
        "        #      .transpose(1, 2).contiguous().view(batch_size, -1, self.d_model))\n",
        "        return self.linears[-1](x)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:13.102019Z",
          "start_time": "2024-04-12T03:02:13.096712Z"
        },
        "id": "7c7bff711b75f437"
      },
      "id": "7c7bff711b75f437",
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FeedForward Class"
      ],
      "metadata": {
        "collapsed": false,
        "id": "3a55f1931832f4e8"
      },
      "id": "3a55f1931832f4e8"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    # todo what is purpose this feed forward layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(config.d_model, config.d_ff)\n",
        "        self.w_2 = nn.Linear(config.d_ff, config.d_model)\n",
        "        self.dropout = nn.Dropout(p=config.dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        this function implement the equation (2)\n",
        "        :param x: [batch_size * seq_len * d_model]\n",
        "        :return: [batch_size * seq_len * d_model]\n",
        "        \"\"\"\n",
        "        # TODO explain the position of the dropout\n",
        "        # according to the equation, this fully connected feed forward layer, this consists of two linear\n",
        "        # transformations with a ReLU activation in between.\n",
        "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:13.744939Z",
          "start_time": "2024-04-12T03:02:13.742423Z"
        },
        "id": "30ebedb53e209bf9"
      },
      "id": "30ebedb53e209bf9",
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding Class"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b379fe4d2a5c651a"
      },
      "id": "b379fe4d2a5c651a"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "\n",
        "class Embedding(nn.Module):\n",
        "    \"\"\"\n",
        "    # todo\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(config.vocab_size, config.d_model)\n",
        "        self.d_model = torch.tensor(config.d_model).to(config.device)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.embedding(x) * torch.sqrt(self.d_model)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    Todo\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        # todo\n",
        "        self.dropout = nn.Dropout(p=config.dropout)\n",
        "        pe = torch.zeros(config.seq_len, config.d_model)\n",
        "        position = torch.arange(0, config.seq_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, config.d_model, 2) * -(math.log(10000.0) / config.d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, embedding: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "\n",
        "        :param x:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        x = embedding + Variable(self.pe[:, :embedding.size(1)], requires_grad=False)\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:14.326057Z",
          "start_time": "2024-04-12T03:02:14.322471Z"
        },
        "id": "ac5d3b38fc40ef03"
      },
      "id": "ac5d3b38fc40ef03",
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LayerNorm Class"
      ],
      "metadata": {
        "collapsed": false,
        "id": "f84da03ea9015000"
      },
      "id": "f84da03ea9015000"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.one_mat = nn.Parameter(torch.ones(config.d_model))\n",
        "        self.zero_mat = nn.Parameter(torch.zeros(config.d_model))\n",
        "        self.eps = config.eps\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "\n",
        "        :param x:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        std = x.std(dim=-1, keepdim=True)\n",
        "        return self.one_mat * (x - mean) / (std + self.eps) + self.zero_mat"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:14.761310Z",
          "start_time": "2024-04-12T03:02:14.758728Z"
        },
        "id": "73d23af9074c6e21"
      },
      "id": "73d23af9074c6e21",
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sublayer Class"
      ],
      "metadata": {
        "collapsed": false,
        "id": "79d5c7f6920785f2"
      },
      "id": "79d5c7f6920785f2"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "\n",
        "class Sublayer(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super(Sublayer, self).__init__()\n",
        "        self.norm = LayerNorm(config)\n",
        "        self.dropout = nn.Dropout(p=config.dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, module: nn.Module) -> torch.Tensor:\n",
        "\n",
        "        return self.dropout(module(self.norm(x))) + x\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:15.200137Z",
          "start_time": "2024-04-12T03:02:15.197780Z"
        },
        "id": "1752a1b77c970e0"
      },
      "id": "1752a1b77c970e0",
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EncoderLayer Class"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6d89d82402be641e"
      },
      "id": "6d89d82402be641e"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(config)\n",
        "        self.ffn = FeedForward(config)\n",
        "        self.sublayers = clone(Sublayer(config), 2)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, src_masking: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.sublayers[0](x, lambda x: self.self_attention(x, x, x, src_masking))\n",
        "        x = self.sublayers[1](x, self.ffn)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:15.653416Z",
          "start_time": "2024-04-12T03:02:15.650878Z"
        },
        "id": "8a55c7954e0b6ee0"
      },
      "id": "8a55c7954e0b6ee0",
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder Class\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "227ad46f3b175254"
      },
      "id": "227ad46f3b175254"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.encoder_layer_list = clone(EncoderLayer(config), config.encoder_layer_num)\n",
        "        self.norm = LayerNorm(config)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, src_masking: torch.Tensor) -> torch.Tensor:\n",
        "        for encoder_layer in self.encoder_layer_list:\n",
        "            x = encoder_layer(x, src_masking)\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:16.162829Z",
          "start_time": "2024-04-12T03:02:16.160136Z"
        },
        "id": "d777c91e1ecb2f65"
      },
      "id": "d777c91e1ecb2f65",
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DecoderLayer Class\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "b680dfdf1e4666f"
      },
      "id": "b680dfdf1e4666f"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(config)\n",
        "        self.cross_attention = MultiHeadAttention(config, is_cross=True)\n",
        "        self.ffn = FeedForward(config)\n",
        "        self.sublayers = clone(Sublayer(config), 3)\n",
        "\n",
        "    def forward(self, memory: torch.Tensor, x: torch.Tensor, src_masking: torch.Tensor,\n",
        "                tgt_masking: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.sublayers[0](x, lambda x: self.self_attention(x, x, x, tgt_masking))\n",
        "        if self.training:\n",
        "            x = self.sublayers[1](x, lambda x: self.cross_attention(x, memory, memory, src_masking))\n",
        "        else:\n",
        "            x = self.sublayers[1](x, lambda x: self.cross_attention(x, memory, memory, src_masking))\n",
        "        x = self.sublayers[2](x, self.ffn)\n",
        "        return x"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:16.550310Z",
          "start_time": "2024-04-12T03:02:16.547100Z"
        },
        "id": "c99b00af3cb57c96"
      },
      "id": "c99b00af3cb57c96",
      "execution_count": 18
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder Class\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9cc87e56c157b657"
      },
      "id": "9cc87e56c157b657"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.decoder_layer_list = clone(DecoderLayer(config), config.decoder_layer_num)\n",
        "        self.norm = LayerNorm(config)\n",
        "\n",
        "    def forward(self, memory: torch.Tensor, x: torch.Tensor,\n",
        "                src_masking: torch.Tensor, tgt_masking: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        for decoder_layer in self.decoder_layer_list:\n",
        "            x = decoder_layer(memory, x, src_masking, tgt_masking)\n",
        "        return self.norm(x)\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:17.207215Z",
          "start_time": "2024-04-12T03:02:17.204848Z"
        },
        "id": "932429a5ed0aad5f"
      },
      "id": "932429a5ed0aad5f",
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Class\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "1efb034794efc1df"
      },
      "id": "1efb034794efc1df"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.embedding = Embedding(config)\n",
        "        self.pe = PositionalEmbedding(config)\n",
        "        self.encoder = Encoder(config)\n",
        "        self.decoder = Decoder(config)\n",
        "        self.linear = nn.Linear(config.d_model, config.vocab_size)\n",
        "\n",
        "    def forward(self, src_x: torch.Tensor, tgt_x: torch.Tensor,\n",
        "                src_masking: torch.Tensor, tgt_masking: torch.Tensor,\n",
        "                memory: tokenizer=None) -> torch.Tensor:\n",
        "        src_embedding = self.embedding(src_x)\n",
        "        tgt_embedding = self.embedding(tgt_x)\n",
        "        src_pe = self.pe(src_embedding)\n",
        "        tgt_pe = self.pe(tgt_embedding)\n",
        "        if memory is None:\n",
        "            memory = self.encoder(src_pe, src_masking)\n",
        "        output = self.decoder(memory, tgt_pe, src_masking, tgt_masking)\n",
        "\n",
        "        logits = self.linear(output)\n",
        "        return {\n",
        "            \"logits\": logits,\n",
        "            \"memory\": memory,\n",
        "            \"output\": output\n",
        "\n",
        "        }\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:18.376860Z",
          "start_time": "2024-04-12T03:02:18.373928Z"
        },
        "id": "1da0b9eaa0af98f"
      },
      "id": "1da0b9eaa0af98f",
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5f98bbbd519a64f8"
      },
      "id": "5f98bbbd519a64f8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prepare the data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "7da3f73a4ad84d59"
      },
      "id": "7da3f73a4ad84d59"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240412_041114-xg23ffhe</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hsubnoedih/from_scratch_transformer_colab/runs/xg23ffhe' target=\"_blank\">self_implemented_transformer_not_converging</a></strong> to <a href='https://wandb.ai/hsubnoedih/from_scratch_transformer_colab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hsubnoedih/from_scratch_transformer_colab' target=\"_blank\">https://wandb.ai/hsubnoedih/from_scratch_transformer_colab</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hsubnoedih/from_scratch_transformer_colab/runs/xg23ffhe' target=\"_blank\">https://wandb.ai/hsubnoedih/from_scratch_transformer_colab/runs/xg23ffhe</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "if not os.path.exists(check_point_folder_path):\n",
        "    os.makedirs(check_point_folder_path)\n",
        "\n",
        "if op_system == \"Darwin\":\n",
        "   train_data_size = str(TRAIN_DATA_SIZE)\n",
        "else:\n",
        "    train_data_size = \"all\"\n",
        "\n",
        "checkpoint_files = os.listdir(check_point_folder_path)\n",
        "checkpoint_file_name = f\"checkpoint_{train_data_size}_batch_size-{BATCH_SIZE}_seq_len-{SEQ_LEN}_encoder_layer_num-{ENCODER_LAYER_NUM}_decoder_layer_num-{DECODER_LAYER_NUM}_d_model-{D_MODEL}_hidden_dim-{HIDDEN_DIM}_num_heads-{NUM_HEADS}_dropout-{DROPOUT}_vocab_size-{VOCAB_SIZE}_epochs-{EPOCHS}_steps-{STEPS}_beta1-{BETA1}_beta2-{BETA2}_epsilon-{EPSILON}_learning_rate-{LEARNING_RATE}_warmup_steps-{WARMUP_STEPS}\"\n",
        "if checkpoint_file_name in checkpoint_files:\n",
        "    # load the model from the checkpoint\n",
        "    transformer = torch.load(check_point_folder_path + \"/\" + checkpoint_file_name)\n",
        "else:\n",
        "    if REPORT_WANDB:\n",
        "        wandb.init(\n",
        "        # set the wandb project where this run will be logged\n",
        "        project=wandb_project_name,\n",
        "        name=run_name,\n",
        "\n",
        "        # track hyperparameters and run metadata\n",
        "        config={\n",
        "            \"batch_size\": BATCH_SIZE,\n",
        "            \"seq_len\": SEQ_LEN,\n",
        "            \"encoder_layer_num\": ENCODER_LAYER_NUM,\n",
        "            \"decoder_layer_num\": DECODER_LAYER_NUM,\n",
        "            \"d_model\": D_MODEL,\n",
        "            \"hidden_dim\": HIDDEN_DIM,\n",
        "            \"num_heads\": NUM_HEADS,\n",
        "            \"dropout\": DROPOUT,\n",
        "            \"vocab_size\": VOCAB_SIZE,\n",
        "            \"epochs\": EPOCHS,\n",
        "            \"steps\": STEPS,\n",
        "            \"beta1\": BETA1,\n",
        "            \"beta2\": BETA2,\n",
        "            \"epsilon\": EPSILON,\n",
        "            \"learning_rate\": LEARNING_RATE,\n",
        "            \"warmup_steps\": WARMUP_STEPS,\n",
        "            \"device\": device.type,\n",
        "            \"timestamp\": time()\n",
        "        }\n",
        "        )\n",
        "\n",
        "transformer_config = TransformerConfig(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    seq_len=SEQ_LEN,\n",
        "    encoder_layer_num=ENCODER_LAYER_NUM,\n",
        "    decoder_layer_num=DECODER_LAYER_NUM,\n",
        "    d_model=D_MODEL,\n",
        "    d_ff=HIDDEN_DIM,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT,\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    device=device,\n",
        "    eps = 1e-6,\n",
        ")\n",
        "# fbceb167aa3fe9025474dbf8f741194f210bbc82"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:20.476213Z",
          "start_time": "2024-04-12T03:02:20.331034Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "dd502d344cb1a83b",
        "outputId": "5354f8ba-eb9c-43c2-e39d-6afeae27cd4a"
      },
      "id": "dd502d344cb1a83b",
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": [
        "## initialize the model and dataset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "d48e81cd09f37cdf"
      },
      "id": "d48e81cd09f37cdf"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "\n",
        "transformer = Transformer(transformer_config)\n",
        "transformer.to(device)\n",
        "\n",
        "# adam with beta1 = 0.9, beta2 = 0.98, epsilon = 1e-9\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2), eps=EPSILON)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100000, gamma=0.5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "wmt14_en_de_tokenizer_dataset = WMT14ENDEDatasetHuggingFace(\n",
        "    en_raw_file_path= data_path + \"raw/train/train.en\",\n",
        "    de_raw_file_path= data_path + \"raw/train/train.de\",\n",
        "    device=device, max_len=SEQ_LEN, data_size=train_data_size)\n",
        "\n",
        "dataloader = DataLoader(wmt14_en_de_tokenizer_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:24.925764Z",
          "start_time": "2024-04-12T03:02:22.233122Z"
        },
        "id": "4b4503b63a81adf3"
      },
      "id": "4b4503b63a81adf3",
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferencing Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "2ed83a62f7123fd5"
      },
      "id": "2ed83a62f7123fd5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save the model function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "2ff9a8b15e8024d9"
      },
      "id": "2ff9a8b15e8024d9"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "def save_model(model, file_path):\n",
        "    torch.save(model, file_path)\n",
        "    print(f\"Model saved at {file_path}\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:27.324370Z",
          "start_time": "2024-04-12T03:02:27.322489Z"
        },
        "id": "b48b5a97b2734299"
      },
      "id": "b48b5a97b2734299",
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute BLEU Score Function"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6d7a6e0ce549798c"
      },
      "id": "6d7a6e0ce549798c"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "def model_evaluate(model, tokenizer, device, max_len=SEQ_LEN):\n",
        "    wmt14_en_de_test_tokenizer_dataset = WMT14ENDEDatasetHuggingFace(\n",
        "        en_raw_file_path= data_path + \"raw/test/newstest2015.en\",\n",
        "        de_raw_file_path= data_path + \"raw/test/newstest2015.de\",\n",
        "        device=device, max_len=SEQ_LEN, data_size=TEST_DATA_SIZE)\n",
        "\n",
        "    test_dataloader = DataLoader(wmt14_en_de_test_tokenizer_dataset, batch_size=8, shuffle=True)\n",
        "    model.eval()\n",
        "    ref_sents_list = []\n",
        "    pred_sents_list = []\n",
        "    for step, data in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
        "        batch_en_tensor = data[\"en_input_ids\"]\n",
        "        padding_mask_en_tensor = data[\"en_padding_mask\"]\n",
        "        ref_sents = data[\"de_sentence_str\"]\n",
        "        # assmble the tgt tensor using the token id of the bos token\n",
        "        batch_de_tensor = torch.tensor([[tokenizer.bos_token_id]] * len(batch_en_tensor), device=device)\n",
        "        padding_mask_de_tensor = torch.ones_like(batch_de_tensor)\n",
        "        memory = None\n",
        "\n",
        "        # data display\n",
        "        # first src sentence in string\n",
        "        # print(f\"src sentence: {data['en_sentence_str'][0]}\")\n",
        "        # first src sentence in token id\n",
        "        # print(f\"src sentence token id: {batch_en_tensor[0]}\")\n",
        "\n",
        "        # first tgt sentence in string initially is just the bos token\n",
        "        # print(f\"tgt sentence: {tokenizer.decode(batch_de_tensor[0])}\")\n",
        "        # first tgt sentence in token id\n",
        "        # print(f\"tgt sentence token id: {batch_de_tensor[0]}\")\n",
        "\n",
        "        # first ground truth sentence\n",
        "        # print(f\"ground truth sentence: {ref_sents[0]}\")\n",
        "\n",
        "\n",
        "        for i in range(max_len):\n",
        "            if memory is None:\n",
        "                res = model(batch_en_tensor, batch_de_tensor, padding_mask_en_tensor, padding_mask_de_tensor)\n",
        "            else:\n",
        "                res = model(batch_en_tensor, batch_de_tensor, padding_mask_en_tensor, padding_mask_de_tensor, memory)\n",
        "            logit = res[\"logits\"]\n",
        "            memory = res[\"memory\"]\n",
        "            logit = torch.softmax(logit, dim=-1)\n",
        "            pred_sents_ids = torch.argmax(logit, dim=-1)\n",
        "            # append the last token of the pred_sents_ids to the tgt_tensor\n",
        "            batch_de_tensor = torch.cat([batch_de_tensor, pred_sents_ids[:, -1].unsqueeze(-1)], dim=-1)\n",
        "            padding_mask_de_tensor = torch.ones_like(batch_de_tensor)\n",
        "            # if all the last token of the pred_sents_ids is padding token, then break\n",
        "            if torch.sum(pred_sents_ids[:, -1] == tokenizer.eos_token_id) == len(pred_sents_ids):\n",
        "               break\n",
        "        # data display\n",
        "        # print(f\"pred sentence token id: {batch_de_tensor[0]}\")\n",
        "        decoded_sents = tokenizer.batch_decode(batch_de_tensor, remove_special_tokens=True)\n",
        "        print(f\"decoded_sents: {decoded_sents[0]}\")\n",
        "\n",
        "        pred_sents_list.extend(decoded_sents)\n",
        "        ref_sents_list.extend([[ref_sent] for ref_sent in ref_sents])\n",
        "        blue_score = compute_bleu(ref_sents_list, pred_sents_list, smooth=True, max_order=4)\n",
        "    return blue_score"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:02:28.635178Z",
          "start_time": "2024-04-12T03:02:28.630974Z"
        },
        "id": "16fc225f64486d60"
      },
      "id": "16fc225f64486d60",
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main loop"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6ad6d6a367dfb7c2"
      },
      "id": "6ad6d6a367dfb7c2"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 200/372404 [01:11<36:46:18,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 200, Loss: 1.4369796514511108\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 400/372404 [02:21<35:51:47,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 400, Loss: 0.9987669587135315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 600/372404 [03:31<35:37:15,  2.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 600, Loss: 0.6785897612571716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 800/372404 [04:41<35:44:02,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 800, Loss: 0.7104177474975586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1000/372404 [05:51<35:44:48,  2.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 1000, Loss: 0.5335140824317932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1200/372404 [07:00<36:55:30,  2.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 1200, Loss: 0.5194545388221741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1400/372404 [08:10<35:51:36,  2.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 1400, Loss: 0.4435024559497833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1600/372404 [09:20<35:43:17,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 1600, Loss: 0.3893871009349823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1800/372404 [10:30<35:47:43,  2.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 1800, Loss: 0.3602859675884247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1999/372404 [11:39<35:23:43,  2.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 2000, Loss: 0.29966822266578674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/272 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|          | 1/272 [00:16<1:12:47, 16.12s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  1%|          | 2/272 [00:31<1:10:43, 15.72s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  1%|          | 3/272 [00:47<1:09:56, 15.60s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  1%|▏         | 4/272 [01:02<1:09:37, 15.59s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n",
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  2%|▏         | 5/272 [01:18<1:10:11, 15.77s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  2%|▏         | 6/272 [01:34<1:10:41, 15.95s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  3%|▎         | 7/272 [01:50<1:10:02, 15.86s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  3%|▎         | 8/272 [02:06<1:09:40, 15.83s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  3%|▎         | 9/272 [02:22<1:09:27, 15.85s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  4%|▎         | 10/272 [02:39<1:10:38, 16.18s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  4%|▍         | 11/272 [02:55<1:10:39, 16.24s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decoded_sents: <sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos><sos>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  4%|▍         | 12/272 [03:11<1:09:54, 16.13s/it]\u001b[A"
          ]
        }
      ],
      "source": [
        "# check if the checkpoint file is already exist, if it is, load the model from the checkpoint\n",
        "if not os.path.exists(check_point_folder_path):\n",
        "    os.makedirs(check_point_folder_path)\n",
        "\n",
        "is_exist = False\n",
        "checkpoint_files = os.listdir(check_point_folder_path)\n",
        "if checkpoint_file_name in checkpoint_files:\n",
        "    # load the model from the checkpoint\n",
        "    transformer = torch.load(check_point_folder_path + \"/\" + checkpoint_file_name)\n",
        "    is_exist = True\n",
        "else:\n",
        "    total_step = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "        epoch_loss = 0\n",
        "        for epoch_step, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
        "            # get the batch\n",
        "            batch_en_tensor = data[\"en_input_ids\"]\n",
        "            batch_de_tensor = data[\"de_input_ids\"]\n",
        "            padding_mask_en_tensor = data[\"en_padding_mask\"]\n",
        "            padding_mask_de_tensor = data[\"de_padding_mask\"]\n",
        "            # forward pass\n",
        "            optimizer.zero_grad()\n",
        "            model_res = transformer(batch_en_tensor, batch_de_tensor, padding_mask_en_tensor, padding_mask_de_tensor)\n",
        "            logit = model_res[\"logits\"]\n",
        "            loss = criterion(logit.view(-1, VOCAB_SIZE), batch_de_tensor.view(-1))\n",
        "            # backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # scheduler.step()\n",
        "            epoch_loss += loss.item()\n",
        "            total_step += 1\n",
        "            if total_step % 100 == 0:\n",
        "                if REPORT_WANDB:\n",
        "                    wandb.log({\"step\": total_step, \"loss\": loss.item()})\n",
        "            if total_step % STEP_LOSS_REPORT == 0:\n",
        "                print(f\"Step: {total_step}, Loss: {loss.item()}\")\n",
        "            if total_step % TEST_BLEU_REPORT == 0:\n",
        "                blue_dict = model_evaluate(transformer, tokenizer, device, max_len=SEQ_LEN)\n",
        "\n",
        "                if REPORT_WANDB:\n",
        "                    wandb.log({\"step\": total_step, \"bleu\": blue_dict[\"bleu\"]})\n",
        "\n",
        "                print(f\"Step: {total_step}, BLEU Score: {blue_dict}\")\n",
        "        if REPORT_WANDB:\n",
        "            wandb.log({\"epoch\": epoch, \"loss\": epoch_loss/len(dataloader)})\n",
        "\n",
        "        print(f\"Epoch: {epoch}, Loss: {epoch_loss/len(dataloader)}\")\n",
        "\n",
        "save_model(transformer, check_point_folder_path + \"/\" + checkpoint_file_name)\n",
        "\n",
        "\n",
        "blue_dict = model_evaluate(transformer, tokenizer, device, max_len=SEQ_LEN)\n",
        "print(f\"BLEU Score: {blue_dict}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if REPORT_WANDB:\n",
        "    wandb.finish()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-04-12T03:10:50.773732Z",
          "start_time": "2024-04-12T03:10:50.753239Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf7183e6f128ee09",
        "outputId": "e8fe18ba-3fb1-4e9e-fea3-5e44adcb0f2a"
      },
      "id": "cf7183e6f128ee09",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "92b1531bad47df7"
      },
      "id": "92b1531bad47df7"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "faf86dee3b06452b"
      },
      "id": "faf86dee3b06452b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b40b5a0ac49149f5bbc940cba6e2f108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_099911e68c6b4c5dbabc4db6b7fff959",
              "IPY_MODEL_d214c16c699f4882a7751b779ab24308",
              "IPY_MODEL_c5baa30234f643deb5fd5a7c9b2eb497"
            ],
            "layout": "IPY_MODEL_55f521fa9c0745c4803142039e44fd88"
          }
        },
        "099911e68c6b4c5dbabc4db6b7fff959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1489b6fe08e46a28960e85c8d1f8343",
            "placeholder": "​",
            "style": "IPY_MODEL_a220915e38d3426482e138718686136f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d214c16c699f4882a7751b779ab24308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b92791da28024a5393ebca22885f6ccc",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f5269ef126c4071afb2cff676103852",
            "value": 26
          }
        },
        "c5baa30234f643deb5fd5a7c9b2eb497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f3e9764a0c04f90941e25877e0c7e33",
            "placeholder": "​",
            "style": "IPY_MODEL_beab08e9aa984211938466c0efff8466",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.82kB/s]"
          }
        },
        "55f521fa9c0745c4803142039e44fd88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1489b6fe08e46a28960e85c8d1f8343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a220915e38d3426482e138718686136f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b92791da28024a5393ebca22885f6ccc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5269ef126c4071afb2cff676103852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f3e9764a0c04f90941e25877e0c7e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beab08e9aa984211938466c0efff8466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e349826e352d481e9d6c71868f51de60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad251a3a3269474da70939d0bc80f5a7",
              "IPY_MODEL_3205734c81554c0fa38386e24efbd33e",
              "IPY_MODEL_f8bde81ee8bc4f38bbc7083ba1a7cf77"
            ],
            "layout": "IPY_MODEL_b4bb5a1212b14da7a06a8bd93ceaefbb"
          }
        },
        "ad251a3a3269474da70939d0bc80f5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b001b38b55447e68d785b37e8ddfdab",
            "placeholder": "​",
            "style": "IPY_MODEL_ece66e52d1c74fd39b6545a4c134bb81",
            "value": "config.json: 100%"
          }
        },
        "3205734c81554c0fa38386e24efbd33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1480cbba1584e34801f1bb83c3af111",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70127ca7070842d1a76aae6001b8bb09",
            "value": 665
          }
        },
        "f8bde81ee8bc4f38bbc7083ba1a7cf77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6782b7bf62514d968967479ebee368f3",
            "placeholder": "​",
            "style": "IPY_MODEL_6a52feaca2bc47c4b27a32768b85a7f2",
            "value": " 665/665 [00:00&lt;00:00, 47.5kB/s]"
          }
        },
        "b4bb5a1212b14da7a06a8bd93ceaefbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b001b38b55447e68d785b37e8ddfdab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ece66e52d1c74fd39b6545a4c134bb81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1480cbba1584e34801f1bb83c3af111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70127ca7070842d1a76aae6001b8bb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6782b7bf62514d968967479ebee368f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a52feaca2bc47c4b27a32768b85a7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b32de8bba8747299743eefef9395c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71beacc4109c431c8327cf2b7ca62101",
              "IPY_MODEL_beedee31a2044be286a1421a98df7b2c",
              "IPY_MODEL_fece2e8f323d4368a5f8e590942ac0c3"
            ],
            "layout": "IPY_MODEL_048449adf5d7404ab23e16d8374967ba"
          }
        },
        "71beacc4109c431c8327cf2b7ca62101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49bf62aed09541128e2e473c0e769276",
            "placeholder": "​",
            "style": "IPY_MODEL_870203723c034efd9fe931aa7a5efe2e",
            "value": "vocab.json: 100%"
          }
        },
        "beedee31a2044be286a1421a98df7b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4dbcfee8e7d4daaa717038de868dbd2",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_597e276606e24ff9a6ebc6e605cf8626",
            "value": 1042301
          }
        },
        "fece2e8f323d4368a5f8e590942ac0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2b0ea5a539e45daa98736a09b33c2fb",
            "placeholder": "​",
            "style": "IPY_MODEL_efabc108040d4cd58514a31faabefa0c",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 3.22MB/s]"
          }
        },
        "048449adf5d7404ab23e16d8374967ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49bf62aed09541128e2e473c0e769276": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "870203723c034efd9fe931aa7a5efe2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4dbcfee8e7d4daaa717038de868dbd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597e276606e24ff9a6ebc6e605cf8626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2b0ea5a539e45daa98736a09b33c2fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efabc108040d4cd58514a31faabefa0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd53f2f2981d425d9da130c3ba65ee38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e054484115a94a79b0ae3cae1b7955e5",
              "IPY_MODEL_f3c7ea0dd40742beafeea3411e3ae840",
              "IPY_MODEL_1244c3ad28c74dceb827533a5b8f08c5"
            ],
            "layout": "IPY_MODEL_048c9f0b8dc042fda9841b27c76b4fca"
          }
        },
        "e054484115a94a79b0ae3cae1b7955e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34693d93ed3244ee9f522c2018b11bbc",
            "placeholder": "​",
            "style": "IPY_MODEL_da9022b798b44275916b6b143cb9604b",
            "value": "merges.txt: 100%"
          }
        },
        "f3c7ea0dd40742beafeea3411e3ae840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2903b1052f840b7bb25e6b635fe59cc",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef612a2381de42dcb4f56dbc3c84da3c",
            "value": 456318
          }
        },
        "1244c3ad28c74dceb827533a5b8f08c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e2785c13fb146cfa5d2ed77fa778584",
            "placeholder": "​",
            "style": "IPY_MODEL_083726e595424387ac44239933aab106",
            "value": " 456k/456k [00:00&lt;00:00, 1.84MB/s]"
          }
        },
        "048c9f0b8dc042fda9841b27c76b4fca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34693d93ed3244ee9f522c2018b11bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da9022b798b44275916b6b143cb9604b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2903b1052f840b7bb25e6b635fe59cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef612a2381de42dcb4f56dbc3c84da3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e2785c13fb146cfa5d2ed77fa778584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083726e595424387ac44239933aab106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6067593c9694fe9918dcc6b239546bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b142be0d847a4e17b90c5897fc3a536e",
              "IPY_MODEL_0678cbcdad69441584b7cbe46338192d",
              "IPY_MODEL_094e33cbfde246378e3cfb90ea7a45f6"
            ],
            "layout": "IPY_MODEL_bb1f1ff7b57042d6841e54818460d84f"
          }
        },
        "b142be0d847a4e17b90c5897fc3a536e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44d1d93cb6b84703b9b611fe0831e548",
            "placeholder": "​",
            "style": "IPY_MODEL_25f68f9763414b09bb4165acc9e97a42",
            "value": "tokenizer.json: 100%"
          }
        },
        "0678cbcdad69441584b7cbe46338192d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0033e0512aef4e1a90323b4a6904d3e6",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_860f2e878c584b4ca959dc204faf87cf",
            "value": 1355256
          }
        },
        "094e33cbfde246378e3cfb90ea7a45f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f3c4895c02944428a27db7fb68f6c0e",
            "placeholder": "​",
            "style": "IPY_MODEL_08aadb7691424a409c849b52cd4422f4",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 3.74MB/s]"
          }
        },
        "bb1f1ff7b57042d6841e54818460d84f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d1d93cb6b84703b9b611fe0831e548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25f68f9763414b09bb4165acc9e97a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0033e0512aef4e1a90323b4a6904d3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "860f2e878c584b4ca959dc204faf87cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f3c4895c02944428a27db7fb68f6c0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08aadb7691424a409c849b52cd4422f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}